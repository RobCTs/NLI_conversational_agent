{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07a2d214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\envs\\my-torch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"multi_woz_v22\")\n",
    "train_data = dataset['train']\n",
    "val_data = dataset['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8833c3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_preprocess(data):\n",
    "    \"\"\"\n",
    "    Filters a list of dictionaries by only including entries with services\n",
    "    either \"restaurant\" or \"hotel\" and having only one service.\n",
    "\n",
    "    Parameters:\n",
    "    - data: list of dictionaries containing a \"services\" key, which is a list of services.\n",
    "\n",
    "    Returns:\n",
    "    - List of filtered dictionaries.\n",
    "    \"\"\"\n",
    "    return [entry for entry in data if set(entry[\"services\"]).issubset({\"restaurant\", \"hotel\"}) and len(entry[\"services\"]) == 1]\n",
    "\n",
    "\n",
    "train_data_filtered = filter_and_preprocess(train_data)\n",
    "val_data_filtered = filter_and_preprocess(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55a3a09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def toDataFrame(raw_data):\n",
    "    # Initialize an empty list to store rows as dictionaries\n",
    "    data = []\n",
    "\n",
    "    # Loop through each dialogue in the training data\n",
    "    for dialogue in raw_data:\n",
    "\n",
    "        # Get the number of turns in this dialogue\n",
    "        num_turns = len(dialogue['turns']['utterance'])\n",
    "\n",
    "        # Loop through each turn in the dialogue\n",
    "        for i in range(num_turns):\n",
    "\n",
    "            # Extract the utterance and corresponding service for this turn\n",
    "            utterance = dialogue['turns']['utterance'][i]\n",
    "            service = dialogue['services']\n",
    "\n",
    "            # Append as a dictionary to the data list\n",
    "            data.append({'Utterance': utterance, 'Service': service})\n",
    "\n",
    "    # Save data as pandas df\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Separate features and labels\n",
    "    X = df['Utterance']\n",
    "    Y = df['Service']\n",
    "    \n",
    "    return X, Y\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f85cfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = toDataFrame(train_data_filtered)\n",
    "X_val, Y_val = toDataFrame(val_data_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5633633f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Guten Tag, I am staying overnight in Cambridge...\n",
       "1        I have 4 different options for you. I have two...\n",
       "2        No, but I'd really like to be on the south end...\n",
       "3        Sure. Does price matter? We can narrow it down...\n",
       "4        No I don't care about the price. Which one do ...\n",
       "                               ...                        \n",
       "17945    nandos serves portuguese food and in the cheap...\n",
       "17946    I would like the address of Nandos restaurant,...\n",
       "17947    Nandos is located in the south part of the cit...\n",
       "17948                                  Thank you, goodbye.\n",
       "17949                                  Thank you good bye.\n",
       "Name: Utterance, Length: 17950, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6928 utterances are about hotels.\n",
    "# 11022 utterances are about restaurants.\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82294d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import DistilBertTokenizer, DistilBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "108f8e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81bdd78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_data(X, Y):\n",
    "    input_encoded = []\n",
    "    attention_masks = []\n",
    "    labels = []\n",
    "    for x,y in zip(X,Y):\n",
    "        encoded = tokenizer.encode_plus(\n",
    "            x, \n",
    "            add_special_tokens=True, \n",
    "            max_length=128, \n",
    "            padding='max_length', \n",
    "            truncation=True, \n",
    "            return_attention_mask=True)\n",
    "        input_encoded.append(encoded['input_ids'])\n",
    "        attention_masks.append(encoded['attention_mask'])\n",
    "        labels.append(0 if y[0] == 'hotel' else 1)\n",
    "    return torch.tensor(input_encoded), torch.tensor(attention_masks), torch.tensor(labels)\n",
    "\n",
    "train_input, train_masks, train_labels = pre_process_data(X_train, Y_train)\n",
    "val_input, val_masks, val_labels = pre_process_data(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40f780a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_input, train_masks, train_labels)\n",
    "val_data = TensorDataset(val_input, val_masks, val_labels)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=16, num_workers=4, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=16, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc3029eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.fc = nn.Linear(768, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :] # selects the [CLS] token position.\n",
    "        logits = self.fc(cls_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e657d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fef56308",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 0: 100%|██████████| 1122/1122 [13:21<00:00,  1.40it/s, training_loss=0.052]\n",
      "Validation Epoch 0: 100%|██████████| 71/71 [00:28<00:00,  2.53it/s, validation_loss=0.055]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training Loss: 0.2594136831623713, Validation Loss: 0.26249390499482694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 1122/1122 [17:50<00:00,  1.05it/s, training_loss=0.064]\n",
      "Validation Epoch 1: 100%|██████████| 71/71 [00:27<00:00,  2.58it/s, validation_loss=0.129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 0.1993416667087485, Validation Loss: 0.28058904231014387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 1122/1122 [17:49<00:00,  1.05it/s, training_loss=0.085]\n",
      "Validation Epoch 2: 100%|██████████| 71/71 [00:27<00:00,  2.54it/s, validation_loss=0.060]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Training Loss: 0.17834211940837297, Validation Loss: 0.27007889954871694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = BertClassifier()\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# For storing training and validation loss\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    \n",
    "    # Initialize tqdm progress bar\n",
    "    train_bar = tqdm(train_loader, desc=f'Training Epoch {epoch}')\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    for batch in train_bar:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update training loss\n",
    "        train_loss += loss.item()\n",
    "        train_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "    \n",
    "    # Average training loss\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # Validation\n",
    "    val_loss = 0.0\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize tqdm progress bar for validation\n",
    "    val_bar = tqdm(val_loader, desc=f'Validation Epoch {epoch}')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_bar:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            \n",
    "            # Forward pass\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            loss = criterion(logits, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_bar.set_postfix({'validation_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "            \n",
    "    # Average validation loss\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    \n",
    "    print(f'Epoch {epoch}, Training Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c220a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\camil\\anaconda3\\envs\\my-torch\\lib\\site-packages (1.3.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\camil\\anaconda3\\envs\\my-torch\\lib\\site-packages (from scikit-learn) (1.24.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\camil\\anaconda3\\envs\\my-torch\\lib\\site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\camil\\anaconda3\\envs\\my-torch\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\camil\\anaconda3\\envs\\my-torch\\lib\\site-packages (from scikit-learn) (3.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 71/71 [00:27<00:00,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8528368794326241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Disable gradient computation\n",
    "with torch.no_grad():\n",
    "    # Initialize tqdm progress bar for validation\n",
    "    val_bar = tqdm(val_loader, desc='Validation')\n",
    "\n",
    "    for batch in val_bar:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(input_ids, attention_mask)\n",
    "\n",
    "        # Get the predicted labels\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "\n",
    "        # Move preds and labels to CPU for further evaluation (if using GPU)\n",
    "        preds = preds.cpu().numpy()\n",
    "        labels = labels.cpu().numpy()\n",
    "\n",
    "        # Extend the list of predictions and labels\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f'Validation Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0dc83c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"topic_classifier_state_dict_4_epochs.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "121fdd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: restaurant\n"
     ]
    }
   ],
   "source": [
    "def predict(model, sentence, tokenizer):\n",
    "    model.eval()\n",
    "    \n",
    "    encoded = tokenizer.encode_plus(\n",
    "        sentence, \n",
    "        add_special_tokens=True, \n",
    "        max_length=256, \n",
    "        padding='max_length', \n",
    "        truncation=True, \n",
    "        return_attention_mask=True)\n",
    "    \n",
    "    input_ids = torch.tensor([encoded['input_ids']], dtype=torch.long).to(device)\n",
    "    attention_mask = torch.tensor([encoded['attention_mask']], dtype=torch.long).to(device)\n",
    "    \n",
    "    # Make a prediction\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, attention_mask)\n",
    "    \n",
    "    # Decode the prediction to label\n",
    "    _, preds = torch.max(logits, dim=1)\n",
    "    label = \"hotel\" if preds.item() == 0 else \"restaurant\"\n",
    "    \n",
    "    return label\n",
    "\n",
    "\n",
    "sentence = \"I would like to reserve for October 12th at 8:00.\"\n",
    "predicted_label = predict(model, sentence, tokenizer)\n",
    "print(\"Predicted label:\", predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2e3bec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
