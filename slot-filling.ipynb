{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-11-21T18:36:52.613509Z",
                    "iopub.status.busy": "2023-11-21T18:36:52.613108Z",
                    "iopub.status.idle": "2023-11-21T18:36:53.426461Z",
                    "shell.execute_reply": "2023-11-21T18:36:53.425591Z",
                    "shell.execute_reply.started": "2023-11-21T18:36:52.613476Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "from datasets import load_dataset\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "from transformers import BertTokenizerFast\n",
                "from torch.utils.data import DataLoader, TensorDataset\n",
                "\n",
                "# Check if GPU is available and set the device accordingly\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "\n",
                "# Load the Train, Validation and Test data\n",
                "\n",
                "dataset = load_dataset(\"multi_woz_v22\")\n",
                "train_data = dataset['train']\n",
                "val_data = dataset['validation']\n",
                "test_data = dataset['test']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-11-21T18:36:53.428336Z",
                    "iopub.status.busy": "2023-11-21T18:36:53.428058Z",
                    "iopub.status.idle": "2023-11-21T18:37:15.734609Z",
                    "shell.execute_reply": "2023-11-21T18:37:15.733602Z",
                    "shell.execute_reply.started": "2023-11-21T18:36:53.428311Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "def filterDomains(data):\n",
                "    \"\"\"\n",
                "    Filters a list of dictionaries by only including entries with services\n",
                "    either \"restaurant\" or \"hotel\" and having only one service.\n",
                "\n",
                "    Parameters:\n",
                "    - data: list of dictionaries containing a \"services\" key, which is a list of services.\n",
                "\n",
                "    Returns:\n",
                "    - List of filtered dictionaries.\n",
                "    \"\"\"\n",
                "    return [entry for entry in data if set(entry[\"services\"]).issubset({\"restaurant\", \"hotel\"})]\n",
                "\n",
                "# Only keep dialogues related to Restaurants or Hotels.\n",
                "\n",
                "train_data_filtered = filterDomains(train_data)\n",
                "val_data_filtered = filterDomains(val_data)\n",
                "test_data_filtered = filterDomains(test_data)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-11-21T18:37:15.736088Z",
                    "iopub.status.busy": "2023-11-21T18:37:15.735820Z",
                    "iopub.status.idle": "2023-11-21T18:37:15.741404Z",
                    "shell.execute_reply": "2023-11-21T18:37:15.740523Z",
                    "shell.execute_reply.started": "2023-11-21T18:37:15.736065Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "print(train_data_filtered[0])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Identifying the slots"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-11-21T18:37:15.743945Z",
                    "iopub.status.busy": "2023-11-21T18:37:15.743528Z",
                    "iopub.status.idle": "2023-11-21T18:37:15.984342Z",
                    "shell.execute_reply": "2023-11-21T18:37:15.983566Z",
                    "shell.execute_reply.started": "2023-11-21T18:37:15.743919Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
                "\n",
                "\n",
                "def label_utterances(dialogue):\n",
                "    labeled_data = []\n",
                "    data = dialogue['turns']\n",
                "    \n",
                "    # Loop through each turn in the dialogue\n",
                "    for i, turn_id in enumerate(data['turn_id']):\n",
                "        utterance = data['utterance'][i]\n",
                "        # Tokenize the utterance and get the offset mappings\n",
                "        encoded_input = tokenizer(utterance, add_special_tokens=False, return_offsets_mapping=True)\n",
                "        tokens = tokenizer.convert_ids_to_tokens(encoded_input['input_ids'])\n",
                "        labels = ['O'] * len(tokens)  # Initialize labels as 'O' (Outside)\n",
                "        offset_mapping = encoded_input['offset_mapping']\n",
                "        # Check if there are slot values for this turn\n",
                "        if 'dialogue_acts' in data and i < len(data['dialogue_acts']):\n",
                "            dialogue_act = data['dialogue_acts'][i]\n",
                "            span_info = dialogue_act.get('span_info', {})\n",
                "            for act_slot_name, act_slot_value, span_start, span_end in zip(\n",
                "                    span_info.get('act_slot_name', []),\n",
                "                    span_info.get('act_slot_value', []),\n",
                "                    span_info.get('span_start', []),\n",
                "                    span_info.get('span_end', [])):\n",
                "                \n",
                "                # Find the tokens that correspond to the start and end indices\n",
                "                # start_token_idx = next((idx for idx, offset in enumerate(offset_mapping) if offset[0] == span_start), None)\n",
                "                # end_token_idx = next((idx for idx, offset in enumerate(offset_mapping) if offset[1] == span_end), None)\n",
                "                \n",
                "                # Utilize the offset_mapping to find the token index for the start and end of the span\n",
                "                start_token_idx = None\n",
                "                end_token_idx = None\n",
                "                \n",
                "                for idx, offset in enumerate(offset_mapping):\n",
                "                    if start_token_idx is None and offset[0] == span_start:\n",
                "                        start_token_idx = idx\n",
                "                    if offset[1] == span_end:\n",
                "                        end_token_idx = idx\n",
                "                        break\n",
                "                \n",
                "                if start_token_idx is not None and end_token_idx is not None:\n",
                "                    if start_token_idx < len(tokens) and end_token_idx < len(tokens):\n",
                "                        # Label tokens using IOB format with the actual ground truth slot value\n",
                "                        labels[start_token_idx] = f\"B-{act_slot_name}\"\n",
                "                        for j in range(start_token_idx + 1, end_token_idx + 1):\n",
                "                            labels[j] = f\"I-{act_slot_name}\"\n",
                "                    else:\n",
                "                        print(f\"Warning: Index out of range for utterance '{utterance}' with span {span_start}-{span_end}\")\n",
                "            \n",
                "            try:\n",
                "                # if the prev_dialogue_act is not None, then we need to label the tokens that are part of the previous dialogue act\n",
                "                prev_dialogue_act = data['dialogue_acts'][i-1]['dialog_act']['act_type'][0] if i > 0 and data['dialogue_acts'][i]['dialog_act']['act_type'][0] else \"\"\n",
                "                current_dialogue_act = data['dialogue_acts'][i]['dialog_act']['act_type'][0] if data['dialogue_acts'][i]['dialog_act']['act_type'][0] else \"\"\n",
                "            except IndexError as e:\n",
                "                prev_dialogue_act = \"\"\n",
                "                current_dialogue_act = \"\"\n",
                "            \n",
                "            dialogue_act_str = f\"{prev_dialogue_act}|{current_dialogue_act}\"\n",
                "            \n",
                "            act_tokens = tokenizer.tokenize(dialogue_act_str)\n",
                "            act_labels = ['X'] * len(act_tokens)\n",
                "            tokens = act_tokens + ['[SEP]'] + tokens  # Add a separator token between acts and the utterance\n",
                "            labels = act_labels + ['X'] + labels  # Add an 'X' label for the separator token\n",
                "\n",
                "        # Store the tokenized utterance along with its labels\n",
                "        labeled_data.append((tokens, labels))\n",
                "        \n",
                "    return labeled_data\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-11-21T18:37:15.985464Z",
                    "iopub.status.busy": "2023-11-21T18:37:15.985196Z",
                    "iopub.status.idle": "2023-11-21T18:37:23.130618Z",
                    "shell.execute_reply": "2023-11-21T18:37:23.129854Z",
                    "shell.execute_reply.started": "2023-11-21T18:37:15.985438Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "def toDF(data, label_function=label_utterances):\n",
                "    all_labeled_data = []\n",
                "    for dialogue in data:\n",
                "        all_labeled_data.extend(label_function(dialogue))\n",
                "    return pd.DataFrame(all_labeled_data, columns=['Tokens', 'Labels'])\n",
                "    \n",
                "# Create DataFrames of labeled utterances\n",
                "train_df = toDF(train_data_filtered)\n",
                "test_df = toDF(test_data_filtered)\n",
                "val_df = toDF(val_data_filtered)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-11-21T18:37:23.132070Z",
                    "iopub.status.busy": "2023-11-21T18:37:23.131779Z",
                    "iopub.status.idle": "2023-11-21T18:37:28.759349Z",
                    "shell.execute_reply": "2023-11-21T18:37:28.758512Z",
                    "shell.execute_reply.started": "2023-11-21T18:37:23.132045Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "train_df.to_excel(\"output.xlsx\")  "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-11-21T18:37:28.760789Z",
                    "iopub.status.busy": "2023-11-21T18:37:28.760488Z",
                    "iopub.status.idle": "2023-11-21T18:37:28.767285Z",
                    "shell.execute_reply": "2023-11-21T18:37:28.766071Z",
                    "shell.execute_reply.started": "2023-11-21T18:37:28.760763Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "print(train_df.shape)\n",
                "print(train_df[\"Tokens\"].iloc[9])\n",
                "print(train_df[\"Labels\"].iloc[9])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-11-21T18:37:28.769588Z",
                    "iopub.status.busy": "2023-11-21T18:37:28.768707Z",
                    "iopub.status.idle": "2023-11-21T18:37:28.847042Z",
                    "shell.execute_reply": "2023-11-21T18:37:28.846130Z",
                    "shell.execute_reply.started": "2023-11-21T18:37:28.769561Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "\n",
                "all_labels = [label for sublist in train_df['Labels'].tolist() for label in sublist]\n",
                "all_labels += [label for sublist in val_df['Labels'].tolist() for label in sublist]\n",
                "all_labels += [label for sublist in test_df['Labels'].tolist() for label in sublist]\n",
                "unique_labels = sorted(set(all_labels))\n",
                "\n",
                "unique_labels.__sizeof__()\n",
                "\n",
                "# We will ignore the 'X' label.\n",
                "unique_labels.remove('X')\n",
                "\n",
                "print(unique_labels)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-11-21T18:37:28.848612Z",
                    "iopub.status.busy": "2023-11-21T18:37:28.848296Z",
                    "iopub.status.idle": "2023-11-21T18:37:28.853027Z",
                    "shell.execute_reply": "2023-11-21T18:37:28.852025Z",
                    "shell.execute_reply.started": "2023-11-21T18:37:28.848586Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "label_map = {label: i for i, label in enumerate(unique_labels)}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def encode_pre_tokenized(pre_tokenized_tokens, tokenizer, max_length):\n",
                "\n",
                "    # Add special tokens\n",
                "    tokens = ['[CLS]'] + pre_tokenized_tokens + ['[SEP]']\n",
                "    \n",
                "    # Initialize the list of word IDs\n",
                "    word_ids = []``\n",
                "\n",
                "    # Word IDs should start from 1 as 0 is reserved for the [CLS] token\n",
                "    current_word_id = 1\n",
                "    \n",
                "    for token in pre_tokenized_tokens:\n",
                "        # Append the word ID to the list. If the token is a continuation of a word (`##` prefix), \n",
                "        # it gets the same word ID as the previous token.\n",
                "\n",
                "        if token == \"[SEP]\" or token == \"[CLS]\":\n",
                "            continue\n",
                "        if token.startswith('##'):\n",
                "            word_ids.append(current_word_id)\n",
                "        else:\n",
                "            word_ids.append(current_word_id)\n",
                "            current_word_id += 1\n",
                "\n",
                "\n",
                "    # Convert tokens to input IDs\n",
                "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
                "\n",
                "    # Create the attention mask\n",
                "    attention_mask = [1] * len(input_ids)\n",
                "\n",
                "    # Check if padding is necessary\n",
                "    padding_length = max_length - len(input_ids)\n",
                "    if padding_length > 0:  # pad the sequence if it is shorter than max_length\n",
                "        input_ids += [tokenizer.pad_token_id] * padding_length\n",
                "        attention_mask += [0] * padding_length\n",
                "    # return a dict \n",
                "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"word_ids\": word_ids}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def decode_input_ids(input_ids, tokenizer):\n",
                "    # Convert input IDs to tokens\n",
                "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
                "    return tokens.replace('##', '')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-11-21T18:37:28.856196Z",
                    "iopub.status.busy": "2023-11-21T18:37:28.855909Z",
                    "iopub.status.idle": "2023-11-21T18:37:28.865832Z",
                    "shell.execute_reply": "2023-11-21T18:37:28.864989Z",
                    "shell.execute_reply.started": "2023-11-21T18:37:28.856166Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "def create_dataset(df, tokenizer, label_map):\n",
                "    # Lists to store the tokenized inputs and labels\n",
                "    input_ids = []\n",
                "    attention_masks = []\n",
                "    label_ids = []\n",
                "\n",
                "    # Iterate over the DataFrame rows\n",
                "    for _, row in df.iterrows():\n",
                "        tokens = row['Tokens']\n",
                "        labels = row['Labels']\n",
                "        \n",
                "        encoded_input = encode_pre_tokenized(tokens, tokenizer, 256)\n",
                "        label_ids_for_tokens = [label_map.get(label, -100) for label in labels] # ignore the 'X' label\n",
                "        \n",
                "        # Create an empty array to hold the final label IDs\n",
                "        aligned_labels = np.ones(len(encoded_input['input_ids']), dtype=int) * -100\n",
                "\n",
                "        # Set labels using the word_ids to align them with tokens\n",
                "        for i, word_id in enumerate(encoded_input[\"word_ids\"]):\n",
                "            if word_id is not None and tokens[word_id] not in [\"[CLS]\", \"[SEP]\"]:\n",
                "                aligned_labels[i] = label_ids_for_tokens[word_id]\n",
                "\n",
                "        # Append the results to the lists\n",
                "        input_ids.append(encoded_input['input_ids'])\n",
                "        attention_masks.append(encoded_input['attention_mask'])\n",
                "        label_ids.append(aligned_labels.tolist())\n",
                "\n",
                "    # Convert lists to tensors\n",
                "    input_ids = torch.tensor(input_ids, dtype=torch.long)\n",
                "    attention_masks = torch.tensor(attention_masks, dtype=torch.long)\n",
                "    label_ids = torch.tensor(label_ids, dtype=torch.long)\n",
                "\n",
                "    # Create the TensorDataset\n",
                "    dataset = TensorDataset(input_ids, attention_masks, label_ids)\n",
                "\n",
                "    return dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-11-21T18:37:28.867065Z",
                    "iopub.status.busy": "2023-11-21T18:37:28.866809Z",
                    "iopub.status.idle": "2023-11-21T18:37:51.257583Z",
                    "shell.execute_reply": "2023-11-21T18:37:51.256553Z",
                    "shell.execute_reply.started": "2023-11-21T18:37:28.867042Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "train_dataloader = DataLoader(create_dataset(train_df,tokenizer,label_map), batch_size=16, shuffle=True)\n",
                "val_dataloader = DataLoader(create_dataset(val_df,tokenizer,label_map), batch_size=16, shuffle=True)\n",
                "test_dataloader = DataLoader(create_dataset(test_df,tokenizer,label_map), batch_size=16, shuffle=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-11-21T18:37:51.259051Z",
                    "iopub.status.busy": "2023-11-21T18:37:51.258758Z",
                    "iopub.status.idle": "2023-11-21T18:37:53.119385Z",
                    "shell.execute_reply": "2023-11-21T18:37:53.118376Z",
                    "shell.execute_reply.started": "2023-11-21T18:37:51.259025Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "from transformers import BertForTokenClassification, BertConfig\n",
                "\n",
                "# Define the number of labels\n",
                "num_labels = len(label_map)  # Make sure label_map is defined in your environment\n",
                "\n",
                "# Create a configuration object with `num_labels` set\n",
                "config = BertConfig.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
                "\n",
                "# Create the model with the standard token classification head\n",
                "model = BertForTokenClassification(config).to(device)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-11-21T18:37:53.120935Z",
                    "iopub.status.busy": "2023-11-21T18:37:53.120606Z",
                    "iopub.status.idle": "2023-11-21T20:00:22.863809Z",
                    "shell.execute_reply": "2023-11-21T20:00:22.862823Z",
                    "shell.execute_reply.started": "2023-11-21T18:37:53.120908Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "from tqdm.auto import tqdm\n",
                "\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
                "criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
                "epochs = 1\n",
                "patience = 2\n",
                "\n",
                "\n",
                "# Initialize the early stopping counter\n",
                "best_val_loss = float('inf')\n",
                "patience_counter = 0\n",
                "\n",
                "# Training loop\n",
                "for epoch in range(epochs):\n",
                "    model.train()\n",
                "    train_loss = 0\n",
                "    train_progress_bar = tqdm(train_dataloader, desc=f'Epoch {epoch+1}/{epochs} Training', leave=False)\n",
                "    \n",
                "    # Training phase\n",
                "    for batch in train_progress_bar:\n",
                "        batch = tuple(t.to(device) for t in batch)\n",
                "        b_input_ids, b_input_mask, b_labels = batch\n",
                "        optimizer.zero_grad()\n",
                "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
                "        loss = outputs.loss\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        train_loss += loss.item()\n",
                "        train_progress_bar.set_postfix(train_loss=loss.item())\n",
                "    \n",
                "    avg_train_loss = train_loss / len(train_dataloader)\n",
                "    print(f'Epoch {epoch + 1}/{epochs} | Train Loss: {avg_train_loss}')\n",
                "\n",
                "    # Validation phase\n",
                "    model.eval()\n",
                "    val_loss = 0\n",
                "    val_progress_bar = tqdm(val_dataloader, desc=f'Epoch {epoch+1}/{epochs} Validation', leave=False)\n",
                "    for batch in val_progress_bar:\n",
                "        batch = tuple(t.to(device) for t in batch)\n",
                "        b_input_ids, b_input_mask, b_labels = batch\n",
                "        with torch.no_grad():\n",
                "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
                "            loss = outputs.loss\n",
                "            val_loss += loss.item()\n",
                "            val_progress_bar.set_postfix(val_loss=loss.item())\n",
                "    \n",
                "    avg_val_loss = val_loss / len(val_dataloader)\n",
                "    print(f'Epoch {epoch + 1}/{epochs} | Validation Loss: {avg_val_loss}')\n",
                "\n",
                "    # Check if the validation loss is lower than the best one seen so far\n",
                "    if avg_val_loss < best_val_loss:\n",
                "        best_val_loss = avg_val_loss\n",
                "        patience_counter = 0\n",
                "        torch.save(model.state_dict(), f'checkpoint_epoch_{epoch+1}.pt')\n",
                "    else:\n",
                "        patience_counter += 1\n",
                "        if patience_counter >= patience:\n",
                "            print('Early stopping!')\n",
                "            break\n",
                "print('Training complete. Final model saved.')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-11-21T20:00:22.865652Z",
                    "iopub.status.busy": "2023-11-21T20:00:22.865393Z",
                    "iopub.status.idle": "2023-11-21T20:01:10.493607Z",
                    "shell.execute_reply": "2023-11-21T20:01:10.492509Z",
                    "shell.execute_reply.started": "2023-11-21T20:00:22.865629Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "!pip install seqeval\n",
                "from seqeval.metrics import classification_report as seqeval_classification_report\n",
                "import numpy as np\n",
                "import torch\n",
                "\n",
                "# Reverse the label map to translate from numeric to string labels\n",
                "label_map_reverse = {v: k for k, v in label_map.items()}\n",
                "\n",
                "model.eval()\n",
                "total_loss = 0\n",
                "all_predictions = []\n",
                "all_true_labels = []\n",
                "\n",
                "with torch.no_grad():\n",
                "    for batch in test_dataloader:\n",
                "        batch = tuple(t.to(device) for t in batch)\n",
                "        b_input_ids, b_attention_masks, b_labels = batch\n",
                "\n",
                "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_attention_masks, labels=b_labels)\n",
                "        loss = outputs.loss\n",
                "        total_loss += loss.item()\n",
                "\n",
                "        # Move logits and labels to CPU\n",
                "        logits = outputs.logits.detach().cpu().numpy()\n",
                "        label_ids = b_labels.to('cpu').numpy()\n",
                "\n",
                "        # Convert logits to token predictions\n",
                "        predictions = np.argmax(logits, axis=-1)\n",
                "\n",
                "        # For each item in the batch...\n",
                "        for i in range(b_input_ids.size(0)):\n",
                "            # Skip predictions for tokens with label_id == -100\n",
                "            pred_label_sequence = []\n",
                "            true_label_sequence = []\n",
                "            for j, (pred_id, label_id) in enumerate(zip(predictions[i], label_ids[i])):\n",
                "                if b_attention_masks[i][j] != 0 and label_id != -100:\n",
                "                    pred_label_sequence.append(label_map_reverse.get(pred_id, 'O'))  # Default to 'O' if key is not found\n",
                "                    true_label_sequence.append(label_map_reverse[label_id])\n",
                "\n",
                "            # Ensure the true and predicted sequences have the same length\n",
                "            if len(true_label_sequence) != len(pred_label_sequence):\n",
                "                print(f\"Length mismatch in sequence {i}: true labels {len(true_label_sequence)} vs. predicted labels {len(pred_label_sequence)}\")\n",
                "                # Output the actual sequences to help diagnose the issue\n",
                "                print(\"True labels:\", true_label_sequence)\n",
                "                print(\"Pred labels:\", pred_label_sequence)\n",
                "                continue\n",
                "\n",
                "            # ...extend the true labels and predicted labels lists\n",
                "            all_true_labels.append(true_label_sequence)\n",
                "            all_predictions.append(pred_label_sequence)\n",
                "\n",
                "# Calculate average loss over all the batches\n",
                "avg_loss = total_loss / len(test_dataloader)\n",
                "print(f\"Test loss: {avg_loss}\")\n",
                "\n",
                "# Use seqeval to compute a classification report\n",
                "seqeval_report = seqeval_classification_report(all_true_labels, all_predictions)\n",
                "print(seqeval_report)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2023-11-21T20:11:06.494839Z",
                    "iopub.status.busy": "2023-11-21T20:11:06.494185Z",
                    "iopub.status.idle": "2023-11-21T20:11:06.521102Z",
                    "shell.execute_reply": "2023-11-21T20:11:06.520333Z",
                    "shell.execute_reply.started": "2023-11-21T20:11:06.494806Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "def query_model(model, tokenizer, label_map, utterance, device):\n",
                "    model.eval()  \n",
                "    \n",
                "    \n",
                "    # Reverse the label map to translate from numeric IDs to string labels\n",
                "    label_map_reverse = {v: k for k, v in label_map.items()}\n",
                "\n",
                "    \n",
                "    # Tokenize the new utterance directly with the tokenizer\n",
                "    encoded_input = tokenizer(\n",
                "        utterance,\n",
                "        add_special_tokens=True,\n",
                "        return_attention_mask=True,\n",
                "        padding='max_length',\n",
                "        truncation=True,\n",
                "        max_length=256,\n",
                "        return_tensors='pt'  # Return PyTorch tensors directly\n",
                "    )\n",
                "    \n",
                "    # Move tensors to the correct device\n",
                "    input_ids = encoded_input['input_ids'].to(device)\n",
                "    attention_masks = encoded_input['attention_mask'].to(device)\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        outputs = model(input_ids, token_type_ids=None, attention_mask=attention_masks)\n",
                "        logits = outputs.logits\n",
                "\n",
                "    # Convert logits to probabilities and get the most likely label index\n",
                "    predictions = torch.argmax(logits, dim=2).squeeze().tolist()\n",
                "\n",
                "    # Map predictions to label strings, ignoring -100 and padding tokens\n",
                "    predicted_labels = [label_map_reverse.get(label_id) for label_id, mask in zip(predictions, attention_masks.squeeze().tolist()) if mask != 0 and label_id != -100][1:-1]\n",
                "\n",
                "    return predicted_labels\n",
                "\n",
                "# Example usage\n",
                "new_utterance = \"Can I book a table for five at a Spanish restaurant, the restaurant must be cheap?\"\n",
                "predicted_labels = query_model(model, tokenizer, label_map, new_utterance, device)\n",
                "print(predicted_labels)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Mapping slots to values"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def label_slots(dialogue):\n",
                "    labeled_data = []\n",
                "    data = dialogue['turns']\n",
                "    \n",
                "    # Loop through each turn in the dialogue\n",
                "    for i, turn_id in enumerate(data['turn_id']):\n",
                "        utterance = data['utterance'][i]\n",
                "        tokens = utterance.split()  \n",
                "\n",
                "        # Check if there are slot values for this turn\n",
                "        if 'dialogue_acts' in data and i < len(data['dialogue_acts']):\n",
                "            dialogue_act = data['dialogue_acts'][i]\n",
                "            span_info = dialogue_act.get('span_info', {})\n",
                "            for act_slot_name, act_slot_value, span_start, span_end in zip(\n",
                "                    span_info.get('act_slot_name', []),\n",
                "                    span_info.get('act_slot_value', []),\n",
                "                    span_info.get('span_start', []),\n",
                "                    span_info.get('span_end', [])):\n",
                "                \n",
                "                # Find the tokens that correspond to the start and end indices\n",
                "                start_token_idx = len(utterance[:span_start].split())\n",
                "                end_token_idx = len(utterance[:span_end].split()) - 1\n",
                "\n",
                "                if start_token_idx < len(tokens) and end_token_idx < len(tokens):\n",
                "                    # Label tokens using IOB format with the actual ground truth slot value\n",
                "                    slot = f\"{utterance[span_start:span_end]}\"\n",
                "                    value = act_slot_value\n",
                "                    \n",
                "                    labeled_data.append((slot, value))\n",
                "                else:\n",
                "                    print(f\"Warning: Index out of range for utterance '{utterance}' with span {span_start}-{span_end}\")\n",
                "                \n",
                "\n",
                "        # Store the tokenized utterance along with its labels\n",
                "        \n",
                "        \n",
                "    return labeled_data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "def slotsToDF(data):\n",
                "    all_labeled_data = []\n",
                "    for dialogue in data:\n",
                "        all_labeled_data.extend(label_slots(dialogue))\n",
                "    return pd.DataFrame(all_labeled_data, columns=['Slots', 'Values'])\n",
                "    \n",
                "# Create DataFrames of labeled utterances\n",
                "train_df = slotsToDF(train_data_filtered)\n",
                "test_df = slotsToDF(test_data_filtered)\n",
                "val_df = slotsToDF(val_data_filtered)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mismatched_rows = train_df[train_df['Slots'] != train_df['Values']]\n",
                "\n",
                "# Display the filtered rows\n",
                "display(mismatched_rows)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def map_indiferece(text):\n",
                "    \n",
                "    indiferences = [\"don't care\", \"any\", \"don't mind\", \"no preference\", \"whatever\", \"doesn't matter\"]\n",
                "    \n",
                "    for indiference in indiferences:\n",
                "        if indiference == text:\n",
                "            return \"dontcare\"\n",
                "        else:\n",
                "            return text\n",
                "    \n",
                "    \n",
                "\n",
                "def text_to_num(text):\n",
                "    \"\"\"\n",
                "    Converts text numbers up to 20 into their integer representations as strings.\n",
                "    If the provided text is not a number or out of range, it returns None.\n",
                "    \"\"\"\n",
                "    text_to_num_dict = {\n",
                "        'zero': '0', 'one': '1', 'two': '2', 'three': '3', 'four': '4', \n",
                "        'five': '5', 'six': '6', 'seven': '7', 'eight': '8', 'nine': '9', \n",
                "        'ten': '10', 'eleven': '11', 'twelve': '12', 'thirteen': '13', \n",
                "        'fourteen': '14', 'fifteen': '15', 'sixteen': '16', 'seventeen': '17', \n",
                "        'eighteen': '18', 'nineteen': '19', 'twenty': '20'\n",
                "    }\n",
                "    # convert to lower case to make the function case-insensitive\n",
                "    text = text.lower()\n",
                "    return text_to_num_dict.get(text, False)\n",
                "\n",
                "\n",
                "# Define the post process function\n",
                "def post_process_slot_value(slot_value):\n",
                "    slot_value = slot_value.lower().strip()\n",
                "    # Check if the slot value is a number\n",
                "    number = text_to_num(slot_value)\n",
                "    if number:\n",
                "        return number\n",
                "    \n",
                "    slot_value = map_indiferece(slot_value)\n",
                "    \n",
                "    return slot_value\n",
                "\n",
                "# Assuming train_df is your DataFrame\n",
                "# Apply the post_process_slot_value function to each value in the 'Slots' column\n",
                "train_df['Slots'] = train_df['Slots'].apply(post_process_slot_value)\n",
                "\n",
                "# Now you can filter out the mismatched rows\n",
                "mismatched_rows = train_df[train_df['Slots'] != train_df['Values'].apply(post_process_slot_value)]\n",
                "\n",
                "# Assuming you want to display these mismatched rows\n",
                "display(mismatched_rows)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "map_indiferece(\"any\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from typing import Dict, List\n",
                "\n",
                "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
                "\n",
                "\n",
                "def label_utterances_with_gt_values(dialogue):\n",
                "    labeled_data = []\n",
                "    data = dialogue['turns']\n",
                "    \n",
                "    # Loop through each turn in the dialogue\n",
                "    for i, turn_id in enumerate(data['turn_id']):\n",
                "        utterance = data['utterance'][i]\n",
                "        # Tokenize the utterance and get the offset mappings\n",
                "        encoded_input = tokenizer(utterance, add_special_tokens=False, return_offsets_mapping=True)\n",
                "        tokens = tokenizer.convert_ids_to_tokens(encoded_input['input_ids'])\n",
                "        labels = ['O'] * len(tokens)  # Initialize labels as 'O' (Outside)\n",
                "        offset_mapping = encoded_input['offset_mapping']\n",
                "        # Check if there are slot values for this turn\n",
                "        if 'dialogue_acts' in data and i < len(data['dialogue_acts']):\n",
                "            dialogue_act = data['dialogue_acts'][i]\n",
                "            span_info = dialogue_act.get('span_info', {})\n",
                "            for act_slot_name, act_slot_value, span_start, span_end in zip(\n",
                "                    span_info.get('act_slot_name', []),\n",
                "                    span_info.get('act_slot_value', []),\n",
                "                    span_info.get('span_start', []),\n",
                "                    span_info.get('span_end', [])):\n",
                "                \n",
                "                # Find the tokens that correspond to the start and end indices\n",
                "                # start_token_idx = next((idx for idx, offset in enumerate(offset_mapping) if offset[0] == span_start), None)\n",
                "                # end_token_idx = next((idx for idx, offset in enumerate(offset_mapping) if offset[1] == span_end), None)\n",
                "                \n",
                "                # Utilize the offset_mapping to find the token index for the start and end of the span\n",
                "                start_token_idx = None\n",
                "                end_token_idx = None\n",
                "                \n",
                "                for idx, offset in enumerate(offset_mapping):\n",
                "                    if start_token_idx is None and offset[0] == span_start:\n",
                "                        start_token_idx = idx\n",
                "                    if offset[1] == span_end:\n",
                "                        end_token_idx = idx\n",
                "                        break\n",
                "                \n",
                "                if start_token_idx is not None and end_token_idx is not None:\n",
                "                    if start_token_idx < len(tokens) and end_token_idx < len(tokens):\n",
                "                        # Label tokens using IOB format with the actual ground truth slot value\n",
                "                        labels[start_token_idx] = f\"B-{act_slot_name}:{act_slot_value}\"\n",
                "                        for j in range(start_token_idx + 1, end_token_idx + 1):\n",
                "                            labels[j] = f\"I-{act_slot_name}:{act_slot_value}\"\n",
                "                    else:\n",
                "                        print(f\"Warning: Index out of range for utterance '{utterance}' with span {span_start}-{span_end}\")\n",
                "            \n",
                "            try:\n",
                "                # if the prev_dialogue_act is not None, then we need to label the tokens that are part of the previous dialogue act\n",
                "                prev_dialogue_act = data['dialogue_acts'][i-1]['dialog_act']['act_type'][0] if i > 0 and data['dialogue_acts'][i]['dialog_act']['act_type'][0] else \"\"\n",
                "                current_dialogue_act = data['dialogue_acts'][i]['dialog_act']['act_type'][0] if data['dialogue_acts'][i]['dialog_act']['act_type'][0] else \"\"\n",
                "            except IndexError as e:\n",
                "                prev_dialogue_act = \"\"\n",
                "                current_dialogue_act = \"\"\n",
                "            \n",
                "            dialogue_act_str = f\"{prev_dialogue_act}|{current_dialogue_act}\"\n",
                "            \n",
                "            act_tokens = tokenizer.tokenize(dialogue_act_str)\n",
                "            act_labels = ['X'] * len(act_tokens)\n",
                "            tokens = act_tokens + ['[SEP]'] + tokens  # Add a separator token between acts and the utterance\n",
                "            labels = act_labels + ['X'] + labels  # Add an 'X' label for the separator token\n",
                "\n",
                "        # Store the tokenized utterance along with its labels\n",
                "        labeled_data.append((tokens, labels))\n",
                "        \n",
                "    return labeled_data\n",
                "\n",
                "\n",
                "class DialogSlotMemory():\n",
                "    slot_list_dict: Dict[str, List[str]] = {}\n",
                "\n",
                "    def __init__(self):\n",
                "        self.slot_list_dict = {}\n",
                "    \n",
                "    def add_slot(self, slot_name: str, slot_value: str):\n",
                "        if slot_name not in self.slot_list_dict:\n",
                "            self.slot_list_dict[slot_name] = []\n",
                "        self.slot_list_dict[slot_name].append(slot_value)\n",
                "    \n",
                "    def get_slot_values(self, slot_name: str):\n",
                "        return self.slot_list_dict[slot_name]\n",
                "\n",
                "    def get_most_recent_slot_value(self, slot_name: str):\n",
                "        return self.slot_list_dict[slot_name][-1] if slot_name in self.slot_list_dict else None\n",
                "\n",
                "    def get_all_slot_values(self):\n",
                "        return self.slot_list_dict\n",
                "\n",
                "    def get_all_slot_names(self):\n",
                "        return self.slot_list_dict.keys()\n",
                "        \n",
                "class ConversationDataset:\n",
                "    id_dialog: str\n",
                "    memory: DialogSlotMemory\n",
                "    dataset: TensorDataset\n",
                "\n",
                "def generate_separate_dialogue_datasets(data, label_function=label_utterances) -> List[ConversationDataset]:\n",
                "    \"\"\"\n",
                "    Generates separate datasets for each dialogue in the provided data.\n",
                "    \n",
                "    Parameters:\n",
                "    - data: list of dictionaries containing a \"services\" key, which is a list of services.\n",
                "    \n",
                "    Returns:\n",
                "    - List of datasets, one for each dialogue.\n",
                "    \"\"\"\n",
                "    datasets = []\n",
                "    for dialogue in data:\n",
                "        # Create a dataset for the current dialogue\n",
                "        dataset = ConversationDataset()\n",
                "        dataset.memory = DialogSlotMemory()\n",
                "        dataset.id_dialog = dialogue['dialogue_id']\n",
                "        dataset.dataset = create_dataset(toDF([dialogue], label_function=label_function), tokenizer, label_map)\n",
                "        datasets.append(dataset)\n",
                "    return datasets\n",
                "\n",
                "\n",
                "def remove_tokens_before_sep(ids: torch.Tensor, tokenizer: BertTokenizerFast):\n",
                "    \"\"\"\n",
                "    Removes all the tokens before the SEP token, including the SEP token itself.\n",
                "\n",
                "    Parameters:\n",
                "    - ids: list of token IDs.\n",
                "    \n",
                "    Returns:\n",
                "    - List of token IDs with sep and all tokens before it removed.\n",
                "    \"\"\"\n",
                "    sep_token_id = tokenizer.sep_token_id\n",
                "    sep_token_index = (ids == sep_token_id).nonzero(as_tuple=True)[0][0]\n",
                "    return ids[sep_token_index+1:]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install seqeval\n",
                "from seqeval.metrics import classification_report as seqeval_classification_report\n",
                "import numpy as np\n",
                "import torch\n",
                "\n",
                "# Load model from checkpoint\n",
                "model.load_state_dict(torch.load('checkpoint_epoch_1.pt'))\n",
                "model.eval()\n",
                "\n",
                "\n",
                "# Separate the test data into separate datasets for each dialogue\n",
                "test_datasets = generate_separate_dialogue_datasets(test_data_filtered)\n",
                "\n",
                "# Reverse the label map to translate from numeric to string labels\n",
                "label_map_reverse = {v: k for k, v in label_map.items()}\n",
                "\n",
                "model.eval()\n",
                "total_loss = 0\n",
                "all_predictions = []\n",
                "all_true_labels = []\n",
                "\n",
                "with torch.no_grad():\n",
                "    for dataset in test_datasets:\n",
                "        # Get the input_ids, attention_masks and labels from the dataset\n",
                "        input_ids = dataset.dataset.tensors[0]\n",
                "        attention_masks = dataset.dataset.tensors[1]\n",
                "        labels = dataset.dataset.tensors[2]\n",
                "\n",
                "        # Move tensors to the correct device\n",
                "        input_ids = input_ids.to(device)\n",
                "        attention_masks = attention_masks.to(device)\n",
                "        labels = labels.to(device)\n",
                "        \n",
                "\n",
                "        outputs = model(input_ids, token_type_ids=None, attention_mask=attention_masks, labels=labels)\n",
                "        loss = outputs.loss\n",
                "        total_loss += loss.item()\n",
                "\n",
                "        # Move logits and labels to CPU\n",
                "        logits = outputs.logits.detach().cpu().numpy()\n",
                "        label_ids = labels.to('cpu').numpy()\n",
                "\n",
                "        # Convert logits to token predictions\n",
                "        predictions = np.argmax(logits, axis=-1)\n",
                "\n",
                "        # For each item in the batch...\n",
                "        for i in range(input_ids.size(0)):\n",
                "            # Skip predictions for tokens with label_id == -100\n",
                "            pred_label_sequence = []\n",
                "            true_label_sequence = []\n",
                "            for j, (pred_id, label_id) in enumerate(zip(predictions[i], label_ids[i])):\n",
                "                if attention_masks[i][j] != 0 and label_id != -100:\n",
                "                    pred_label_sequence.append(label_map_reverse.get(pred_id, 'O'))\n",
                "\n",
                "                    # Get the true label from the dataset\n",
                "                    true_label_id = label_ids[i][j]\n",
                "                    true_label_sequence.append(label_map_reverse[true_label_id])\n",
                "\n",
                "            # Ensure the true and predicted sequences have the same length\n",
                "            if len(true_label_sequence) != len(pred_label_sequence):\n",
                "                print(f\"Length mismatch in sequence {i}: true labels {len(true_label_sequence)} vs. predicted labels {len(pred_label_sequence)}\")\n",
                "                # Output the actual sequences to help diagnose the issue\n",
                "                print(\"True labels:\", true_label_sequence)\n",
                "                print(\"Pred labels:\", pred_label_sequence)\n",
                "                continue\n",
                "                \n",
                "            # ...extend the true labels and predicted labels lists\n",
                "            all_true_labels.append(true_label_sequence)\n",
                "            all_predictions.append(pred_label_sequence)\n",
                "            \n",
                "            # Map slot values to slot names based on the predicted labels and add them to the memory\n",
                "            # Skip all the tokens before (and including) the [SEP] token           \n",
                "            ids = dataset.dataset.tensors[0][i][1:]\n",
                "            ids = remove_tokens_before_sep(ids, tokenizer)\n",
                "            for token, pred_label in zip(ids, pred_label_sequence):\n",
                "                if pred_label != 'O':\n",
                "                    slot_name = pred_label[2:]\n",
                "                    \n",
                "                    # Get the slot value\n",
                "                    slot_value = tokenizer.convert_tokens_to_string([tokenizer.convert_ids_to_tokens(token.item())])                    \n",
                "                    dataset.memory.add_slot(slot_name, slot_value)\n",
                "            \n",
                "            # Print the memory for the current dialogue\n",
                "            print(f\"Memory for dialogue {dataset.id_dialog}: {dataset.memory.get_all_slot_values()}\")\n",
                "\n",
                "# Calculate average loss over all the batches\n",
                "avg_loss = total_loss / len(test_datasets)\n",
                "print(f\"Test loss: {avg_loss}\")\n",
                "\n",
                "# Use seqeval to compute a classification report\n",
                "seqeval_report = seqeval_classification_report(all_true_labels, all_predictions)\n",
                "print(seqeval_report)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Full evaluation using memory substitution for \"same\" and using concatenating values and filling the slots\n",
                "\n",
                "!pip install seqeval\n",
                "from seqeval.metrics import classification_report as seqeval_classification_report\n",
                "import numpy as np\n",
                "import torch\n",
                "\n",
                "# Load model from checkpoint\n",
                "model.load_state_dict(torch.load('checkpoint_epoch_1.pt'))\n",
                "model.eval()\n",
                "\n",
                "\n",
                "# Separate the test data into separate datasets for each dialogue\n",
                "test_datasets = generate_separate_dialogue_datasets(test_data_filtered)\n",
                "test_datasets_with_values = generate_separate_dialogue_datasets(test_data_filtered, label_function=label_utterances_with_gt_values)\n",
                "\n",
                "# Reverse t\n",
                "# The label map to translate from numeric to string labels\n",
                "label_map_reverse = {v: k for k, v in label_map.items()}\n",
                "\n",
                "model.eval()\n",
                "total_loss = 0\n",
                "all_predictions = []\n",
                "all_true_labels = []\n",
                "all_predictions_with_values = []\n",
                "\n",
                "with torch.no_grad():\n",
                "    for dataset in test_datasets:\n",
                "        # Get the input_ids, attention_masks and labels from the dataset\n",
                "        input_ids = dataset.dataset.tensors[0]\n",
                "        attention_masks = dataset.dataset.tensors[1]\n",
                "        labels = dataset.dataset.tensors[2]\n",
                "\n",
                "        # Move tensors to the correct device\n",
                "        input_ids = input_ids.to(device)\n",
                "        attention_masks = attention_masks.to(device)\n",
                "        labels = labels.to(device)\n",
                "        \n",
                "\n",
                "        outputs = model(input_ids, token_type_ids=None, attention_mask=attention_masks, labels=labels)\n",
                "        loss = outputs.loss\n",
                "        total_loss += loss.item()\n",
                "\n",
                "        # Move logits and labels to CPU\n",
                "        logits = outputs.logits.detach().cpu().numpy()\n",
                "        label_ids = labels.to('cpu').numpy()\n",
                "\n",
                "        # Convert logits to token predictions\n",
                "        predictions = np.argmax(logits, axis=-1)\n",
                "\n",
                "        # For each item in the batch...\n",
                "        for i in range(input_ids.size(0)):\n",
                "            # Skip predictions for tokens with label_id == -100\n",
                "            pred_label_sequence = []\n",
                "            true_label_sequence = []\n",
                "            for j, (pred_id, label_id) in enumerate(zip(predictions[i], label_ids[i])):\n",
                "                if attention_masks[i][j] != 0 and label_id != -100:\n",
                "                    # Get the slot name from the predicted label\n",
                "                    pred_label_sequence.append(label_map_reverse.get(pred_id, 'O'))\n",
                "\n",
                "                    # Get the true label from the dataset\n",
                "                    true_label_id = label_ids[i][j]\n",
                "                    true_label_sequence.append(label_map_reverse[true_label_id])\n",
                "\n",
                "            # Ensure the true and predicted sequences have the same length\n",
                "            if len(true_label_sequence) != len(pred_label_sequence):\n",
                "                print(f\"Length mismatch in sequence {i}: true labels {len(true_label_sequence)} vs. predicted labels {len(pred_label_sequence)}\")\n",
                "                # Output the actual sequences to help diagnose the issue\n",
                "                print(\"True labels:\", true_label_sequence)\n",
                "                print(\"Pred labels:\", pred_label_sequence)\n",
                "                continue\n",
                "                \n",
                "            # ...extend the true labels and predicted labels lists\n",
                "            all_true_labels.append(true_label_sequence)\n",
                "            all_predictions.append(pred_label_sequence)\n",
                "            \n",
                "            # Map slot values to slot names based on the predicted labels and add them to the memory\n",
                "            # Skip all the tokens before (and including) the [SEP] token           \n",
                "            ids = dataset.dataset.tensors[0][i][1:]\n",
                "            ids = remove_tokens_before_sep(ids, tokenizer)\n",
                "\n",
                "            pred_label_value_sequence = []\n",
                "            for token_id, pred_label in zip(ids, pred_label_sequence):\n",
                "                if pred_label != 'O':\n",
                "                    slot_name = pred_label[2:]\n",
                "                    \n",
                "                    # Get the slot value\n",
                "                    slot_value = decode_input_ids(token_id.item(), tokenizer)\n",
                "                    dataset.memory.add_slot(slot_name, slot_value)\n",
                "\n",
                "                    pred_label_value_sequence.append(f\"{pred_label}:{slot_value}\")\n",
                "                \n",
                "            all_predictions_with_values.append(pred_label_value_sequence)\n",
                "            \n",
                "            # Print the memory for the current dialogue\n",
                "            print(f\"Memory for dialogue {dataset.id_dialog}: {dataset.memory.get_all_slot_values()}\")\n",
                "\n",
                "# Calculate average loss over all the batches\n",
                "avg_loss = total_loss / len(test_datasets)\n",
                "print(f\"Test loss: {avg_loss}\")\n",
                "\n",
                "# Use seqeval to compute a classification report\n",
                "seqeval_report = seqeval_classification_report(all_true_labels, all_predictions)\n",
                "print(seqeval_report)"
            ]
        }
    ],
    "metadata": {
        "kaggle": {
            "accelerator": "gpu",
            "dataSources": [],
            "dockerImageVersionId": 30588,
            "isGpuEnabled": true,
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook"
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
