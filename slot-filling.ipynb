{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\nimport torch\nimport torch.nn as nn\nfrom transformers import BertTokenizerFast\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# Check if GPU is available and set the device accordingly\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load the Train, Validation and Test data\n\ndataset = load_dataset(\"multi_woz_v22\")\ntrain_data = dataset['train']\nval_data = dataset['validation']\ntest_data = dataset['test']","metadata":{"execution":{"iopub.status.busy":"2023-11-21T09:11:05.536990Z","iopub.execute_input":"2023-11-21T09:11:05.537323Z","iopub.status.idle":"2023-11-21T09:12:04.007624Z","shell.execute_reply.started":"2023-11-21T09:11:05.537298Z","shell.execute_reply":"2023-11-21T09:12:04.006648Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/3.10k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbc080c6806f40d5924ce26b4adba617"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/2.77k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1888d930c6d45a982b01a74d6e3e441"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset multi_woz_v22/v2.2_active_only (download: 263.78 MiB, generated: 49.33 MiB, post-processed: Unknown size, total: 313.11 MiB) to /root/.cache/huggingface/datasets/multi_woz_v22/v2.2_active_only/2.2.0/7452f16a8b502e97df5c04cc4ee5436464762fa93b1ce778dd14181e79d8b51a...\n                ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files #3:   0%|          | 0/2 [00:00<?, ?obj/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85fcab0b5bb2433fa6def987a3847df9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data files #9:   0%|          | 0/1 [00:00<?, ?obj/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4072c5ba04f24c3c9a8c070662eefd90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data files #5:   0%|          | 0/2 [00:00<?, ?obj/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20e0decfe045418585d43aebbc68cc40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data files #1:   0%|          | 0/2 [00:00<?, ?obj/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f19f5d5f2b7548408cca849550f564ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data files #2:   0%|          | 0/2 [00:00<?, ?obj/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c85756aa768c402381330b5f19d88759"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data files #6:   0%|          | 0/1 [00:00<?, ?obj/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69dbf8d59d254fd5be00076616a2b2d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data files #14:   0%|          | 0/1 [00:00<?, ?obj/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a069999b77d8427a9526495845b2ddf3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data files #0:   0%|          | 0/2 [00:00<?, ?obj/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"802b29daf83847cfb1f7a6d87c06aa75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data files #15:   0%|          | 0/1 [00:00<?, ?obj/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b0a7efc1da44bf5a9d000725e2dca0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data files #4:   0%|          | 0/2 [00:00<?, ?obj/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa6dc8a5c41e472bac9b7b98db4c3dfd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data files #13:   0%|          | 0/1 [00:00<?, ?obj/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd281c1d64d94a4ab64d980fabf8d8a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data files #7:   0%|          | 0/1 [00:00<?, ?obj/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9be3345c727f4f35a8b5eff8c372008f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data files #8:   0%|          | 0/1 [00:00<?, ?obj/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ef51952b7aa488c80f616510cdda1f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data files #12:   0%|          | 0/1 [00:00<?, ?obj/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41d4acee0d8c44eeb2359902d9f184da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data files #11:   0%|          | 0/1 [00:00<?, ?obj/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6c7ce5162584ea4866fd18abed71bba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data files #10:   0%|          | 0/1 [00:00<?, ?obj/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"721c9d49254e423290f755de424f3bde"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/454k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18c5a5c2b1f24769a6a251dac6a45416"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/444k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbf4bd397a1f4fd290c130ec3c9065da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/439k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd16ee6f3811449e984455b644716f33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/452k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3be699919b74075993e1217d205150b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/440k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37112d0060194198925ee2bcc81b993c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f9a012d63b841ab92c3f9fd606612c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/215k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d21c5c16094341c88bf1d5dd2361c81d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/452k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e5e7abc1d2345bb8ecb8c12d2a7ae12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/457k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20a650006a9d4ea3b14bcbcce2ae5ee1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/448k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bfa98c28f7d4a3cb3a94624883efc01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/465k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"994200bffd904e46b05ed6e7a40dda3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/508k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f504fcfa8fbe457299c80666390d9b89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/467k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9954030924394b8dbc790a0abd27a207"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/439k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ffc5e74dca14824b15489e1ae1b3feb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/509k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e87cb265aa63487798951b26b146761e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/453k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1efc33fcedeb4aeca7e6dc9e512d0506"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/432k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5a2829dead54536b24289b1656d200e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/4.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"243599b96a6e4959b2c9429ad8267f21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/445k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"086a53d212b74d49952c42a28b0520ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/439k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e49617e20574dc18f9253def44d4d87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/449k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3dcbed1831794379930f4bf8d1aecb14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/459k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5212d38c4e5a49b2abaafd4faef58941"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/22 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f1cdd1cf6054f4b8a4fb0f43f2ed668"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/8437 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset multi_woz_v22 downloaded and prepared to /root/.cache/huggingface/datasets/multi_woz_v22/v2.2_active_only/2.2.0/7452f16a8b502e97df5c04cc4ee5436464762fa93b1ce778dd14181e79d8b51a. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee204c2fc5c74b638bfe53f8311fb51a"}},"metadata":{}}]},{"cell_type":"code","source":"def filterDomains(data):\n    \"\"\"\n    Filters a list of dictionaries by only including entries with services\n    either \"restaurant\" or \"hotel\" and having only one service.\n\n    Parameters:\n    - data: list of dictionaries containing a \"services\" key, which is a list of services.\n\n    Returns:\n    - List of filtered dictionaries.\n    \"\"\"\n    return [entry for entry in data if set(entry[\"services\"]).issubset({\"restaurant\", \"hotel\"})]\n\n# Only keep dialogues related to Restaurants or Hotels.\n\ntrain_data_filtered = filterDomains(train_data)\nval_data_filtered = filterDomains(val_data)\ntest_data_filtered = filterDomains(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T09:12:04.009403Z","iopub.execute_input":"2023-11-21T09:12:04.009867Z","iopub.status.idle":"2023-11-21T09:12:25.763408Z","shell.execute_reply.started":"2023-11-21T09:12:04.009838Z","shell.execute_reply":"2023-11-21T09:12:25.762390Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"print(train_data_filtered[0])","metadata":{"execution":{"iopub.status.busy":"2023-11-21T09:12:25.764683Z","iopub.execute_input":"2023-11-21T09:12:25.765032Z","iopub.status.idle":"2023-11-21T09:12:25.771046Z","shell.execute_reply.started":"2023-11-21T09:12:25.764999Z","shell.execute_reply":"2023-11-21T09:12:25.770082Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"{'dialogue_id': 'PMUL4398.json', 'services': ['restaurant', 'hotel'], 'turns': {'turn_id': ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11'], 'speaker': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1], 'utterance': ['i need a place to dine in the center thats expensive', 'I have several options for you; do you prefer African, Asian, or British food?', 'Any sort of food would be fine, as long as it is a bit expensive. Could I get the phone number for your recommendation?', 'There is an Afrian place named Bedouin in the centre. How does that sound?', 'Sounds good, could I get that phone number? Also, could you recommend me an expensive hotel?', \"Bedouin's phone is 01223367660. As far as hotels go, I recommend the University Arms Hotel in the center of town.\", 'Yes. Can you book it for me?', 'Sure, when would you like that reservation?', 'i want to book it for 2 people and 2 nights starting from saturday.', 'Your booking was successful. Your reference number is FRGZWQL2 . May I help you further?', 'That is all I need to know. Thanks, good bye.', 'Thank you so much for Cambridge TownInfo centre. Have a great day!'], 'frames': [{'service': ['restaurant', 'hotel'], 'state': [{'active_intent': 'find_restaurant', 'requested_slots': [], 'slots_values': {'slots_values_name': ['restaurant-area', 'restaurant-pricerange'], 'slots_values_list': [['centre'], ['expensive']]}}, {'active_intent': 'find_hotel', 'requested_slots': [], 'slots_values': {'slots_values_name': [], 'slots_values_list': []}}], 'slots': [{'slot': [], 'value': [], 'start': [], 'exclusive_end': [], 'copy_from': [], 'copy_from_value': []}, {'slot': [], 'value': [], 'start': [], 'exclusive_end': [], 'copy_from': [], 'copy_from_value': []}]}, {'service': [], 'state': [], 'slots': []}, {'service': ['restaurant', 'hotel'], 'state': [{'active_intent': 'find_restaurant', 'requested_slots': ['restaurant-food'], 'slots_values': {'slots_values_name': ['restaurant-area', 'restaurant-pricerange'], 'slots_values_list': [['centre'], ['expensive']]}}, {'active_intent': 'find_hotel', 'requested_slots': [], 'slots_values': {'slots_values_name': [], 'slots_values_list': []}}], 'slots': [{'slot': [], 'value': [], 'start': [], 'exclusive_end': [], 'copy_from': [], 'copy_from_value': []}, {'slot': [], 'value': [], 'start': [], 'exclusive_end': [], 'copy_from': [], 'copy_from_value': []}]}, {'service': [], 'state': [], 'slots': []}, {'service': ['restaurant', 'hotel'], 'state': [{'active_intent': 'find_restaurant', 'requested_slots': ['restaurant-phone'], 'slots_values': {'slots_values_name': ['restaurant-area', 'restaurant-name', 'restaurant-pricerange'], 'slots_values_list': [['centre'], ['bedouin'], ['expensive']]}}, {'active_intent': 'find_hotel', 'requested_slots': [], 'slots_values': {'slots_values_name': ['hotel-pricerange', 'hotel-type'], 'slots_values_list': [['expensive'], ['hotel']]}}], 'slots': [{'slot': [], 'value': [], 'start': [], 'exclusive_end': [], 'copy_from': [], 'copy_from_value': []}, {'slot': [], 'value': [], 'start': [], 'exclusive_end': [], 'copy_from': [], 'copy_from_value': []}]}, {'service': [], 'state': [], 'slots': []}, {'service': ['hotel'], 'state': [{'active_intent': 'find_hotel', 'requested_slots': [], 'slots_values': {'slots_values_name': ['hotel-name', 'hotel-pricerange', 'hotel-type'], 'slots_values_list': [['university arms hotel'], ['expensive'], ['hotel']]}}], 'slots': [{'slot': [], 'value': [], 'start': [], 'exclusive_end': [], 'copy_from': [], 'copy_from_value': []}]}, {'service': [], 'state': [], 'slots': []}, {'service': ['hotel'], 'state': [{'active_intent': 'book_hotel', 'requested_slots': [], 'slots_values': {'slots_values_name': ['hotel-bookday', 'hotel-bookpeople', 'hotel-bookstay', 'hotel-name', 'hotel-pricerange', 'hotel-type'], 'slots_values_list': [['saturday'], ['2'], ['2'], ['university arms hotel'], ['expensive'], ['hotel']]}}], 'slots': [{'slot': [], 'value': [], 'start': [], 'exclusive_end': [], 'copy_from': [], 'copy_from_value': []}]}, {'service': [], 'state': [], 'slots': []}, {'service': [], 'state': [], 'slots': []}, {'service': [], 'state': [], 'slots': []}], 'dialogue_acts': [{'dialog_act': {'act_type': ['Restaurant-Inform'], 'act_slots': [{'slot_name': ['area', 'pricerange'], 'slot_value': ['centre', 'expensive']}]}, 'span_info': {'act_type': ['Restaurant-Inform', 'Restaurant-Inform'], 'act_slot_name': ['area', 'pricerange'], 'act_slot_value': ['centre', 'expensive'], 'span_start': [30, 43], 'span_end': [36, 52]}}, {'dialog_act': {'act_type': ['Restaurant-Inform', 'Restaurant-Select'], 'act_slots': [{'slot_name': ['choice'], 'slot_value': ['several']}, {'slot_name': ['food', 'food', 'food'], 'slot_value': ['African', 'Asian', 'British']}]}, 'span_info': {'act_type': ['Restaurant-Inform', 'Restaurant-Select', 'Restaurant-Select', 'Restaurant-Select'], 'act_slot_name': ['choice', 'food', 'food', 'food'], 'act_slot_value': ['several', 'African', 'Asian', 'British'], 'span_start': [7, 46, 55, 65], 'span_end': [14, 53, 60, 72]}}, {'dialog_act': {'act_type': ['Restaurant-Request'], 'act_slots': [{'slot_name': ['food'], 'slot_value': ['?']}]}, 'span_info': {'act_type': [], 'act_slot_name': [], 'act_slot_value': [], 'span_start': [], 'span_end': []}}, {'dialog_act': {'act_type': ['Restaurant-Inform'], 'act_slots': [{'slot_name': ['area', 'food', 'name'], 'slot_value': ['centre', 'Afrian', 'Bedouin']}]}, 'span_info': {'act_type': ['Restaurant-Inform', 'Restaurant-Inform', 'Restaurant-Inform'], 'act_slot_name': ['food', 'name', 'area'], 'act_slot_value': ['Afrian', 'Bedouin', 'centre'], 'span_start': [12, 31, 46], 'span_end': [18, 38, 52]}}, {'dialog_act': {'act_type': ['Hotel-Inform', 'Restaurant-Request'], 'act_slots': [{'slot_name': ['pricerange', 'type'], 'slot_value': ['expensive', 'hotel']}, {'slot_name': ['phone'], 'slot_value': ['?']}]}, 'span_info': {'act_type': ['Hotel-Inform', 'Hotel-Inform'], 'act_slot_name': ['pricerange', 'type'], 'act_slot_value': ['expensive', 'hotel'], 'span_start': [76, 86], 'span_end': [85, 91]}}, {'dialog_act': {'act_type': ['Hotel-Recommend', 'Restaurant-Inform'], 'act_slots': [{'slot_name': ['area', 'name'], 'slot_value': ['center of town', 'the University Arms Hotel']}, {'slot_name': ['name', 'phone'], 'slot_value': ['Bedouin', '01223367660']}]}, 'span_info': {'act_type': ['Restaurant-Inform', 'Restaurant-Inform', 'Hotel-Recommend', 'Hotel-Recommend'], 'act_slot_name': ['name', 'phone', 'name', 'area'], 'act_slot_value': ['Bedouin', '01223367660', 'the University Arms Hotel', 'center of town'], 'span_start': [0, 19, 65, 98], 'span_end': [7, 30, 90, 112]}}, {'dialog_act': {'act_type': ['Hotel-Inform'], 'act_slots': [{'slot_name': ['none'], 'slot_value': ['none']}]}, 'span_info': {'act_type': [], 'act_slot_name': [], 'act_slot_value': [], 'span_start': [], 'span_end': []}}, {'dialog_act': {'act_type': ['Booking-Request'], 'act_slots': [{'slot_name': ['bookday'], 'slot_value': ['?']}]}, 'span_info': {'act_type': [], 'act_slot_name': [], 'act_slot_value': [], 'span_start': [], 'span_end': []}}, {'dialog_act': {'act_type': ['Hotel-Inform'], 'act_slots': [{'slot_name': ['bookday', 'bookpeople', 'bookstay'], 'slot_value': ['saturday', '2', '2']}]}, 'span_info': {'act_type': ['Hotel-Inform', 'Hotel-Inform', 'Hotel-Inform'], 'act_slot_name': ['bookstay', 'bookpeople', 'bookday'], 'act_slot_value': ['2', '2', 'saturday'], 'span_start': [22, 35, 58], 'span_end': [23, 36, 66]}}, {'dialog_act': {'act_type': ['Booking-Book', 'general-reqmore'], 'act_slots': [{'slot_name': ['ref'], 'slot_value': ['FRGZWQL2']}, {'slot_name': ['none'], 'slot_value': ['none']}]}, 'span_info': {'act_type': ['Booking-Book'], 'act_slot_name': ['ref'], 'act_slot_value': ['FRGZWQL2'], 'span_start': [54], 'span_end': [62]}}, {'dialog_act': {'act_type': ['general-bye'], 'act_slots': [{'slot_name': ['none'], 'slot_value': ['none']}]}, 'span_info': {'act_type': [], 'act_slot_name': [], 'act_slot_value': [], 'span_start': [], 'span_end': []}}, {'dialog_act': {'act_type': ['general-bye', 'general-welcome'], 'act_slots': [{'slot_name': ['none'], 'slot_value': ['none']}, {'slot_name': ['none'], 'slot_value': ['none']}]}, 'span_info': {'act_type': [], 'act_slot_name': [], 'act_slot_value': [], 'span_start': [], 'span_end': []}}]}}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Identifying the slots","metadata":{}},{"cell_type":"code","source":"tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n\n\ndef label_utterances(dialogue):\n    labeled_data = []\n    data = dialogue['turns']\n    \n    # Loop through each turn in the dialogue\n    for i, turn_id in enumerate(data['turn_id']):\n        utterance = data['utterance'][i]\n        # Tokenize the utterance and get the offset mappings\n        encoded_input = tokenizer(utterance, add_special_tokens=False, return_offsets_mapping=True)\n        tokens = tokenizer.convert_ids_to_tokens(encoded_input['input_ids'])\n        labels = ['O'] * len(tokens)  # Initialize labels as 'O' (Outside)\n        offset_mapping = encoded_input['offset_mapping']\n        # Check if there are slot values for this turn\n        if 'dialogue_acts' in data and i < len(data['dialogue_acts']):\n            dialogue_act = data['dialogue_acts'][i]\n            span_info = dialogue_act.get('span_info', {})\n            for act_slot_name, act_slot_value, span_start, span_end in zip(\n                    span_info.get('act_slot_name', []),\n                    span_info.get('act_slot_value', []),\n                    span_info.get('span_start', []),\n                    span_info.get('span_end', [])):\n                \n                # Find the tokens that correspond to the start and end indices\n                # start_token_idx = next((idx for idx, offset in enumerate(offset_mapping) if offset[0] == span_start), None)\n                # end_token_idx = next((idx for idx, offset in enumerate(offset_mapping) if offset[1] == span_end), None)\n                \n                # Utilize the offset_mapping to find the token index for the start and end of the span\n                start_token_idx = None\n                end_token_idx = None\n                \n                for idx, offset in enumerate(offset_mapping):\n                    if start_token_idx is None and offset[0] == span_start:\n                        start_token_idx = idx\n                    if offset[1] == span_end:\n                        end_token_idx = idx\n                        break\n                \n                if start_token_idx is not None and end_token_idx is not None:\n                    if start_token_idx < len(tokens) and end_token_idx < len(tokens):\n                        # Label tokens using IOB format with the actual ground truth slot value\n                        labels[start_token_idx] = f\"B-{act_slot_name}\"\n                        for j in range(start_token_idx + 1, end_token_idx + 1):\n                            labels[j] = f\"I-{act_slot_name}\"\n                    else:\n                        print(f\"Warning: Index out of range for utterance '{utterance}' with span {span_start}-{span_end}\")\n\n        # Store the tokenized utterance along with its labels\n        labeled_data.append((tokens, labels))\n        \n    return labeled_data\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T09:12:25.773820Z","iopub.execute_input":"2023-11-21T09:12:25.774190Z","iopub.status.idle":"2023-11-21T09:12:29.104900Z","shell.execute_reply.started":"2023-11-21T09:12:25.774145Z","shell.execute_reply":"2023-11-21T09:12:29.103960Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"610895ac07684f88bb2e19971b95e150"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c9a6860fbdb4817aa633394b2b5e4a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"634a2e778bea4286b48e406e77aedcae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03b633eff192427989b5669a4523a9df"}},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ndef toDF(data):\n    all_labeled_data = []\n    for dialogue in data:\n        all_labeled_data.extend(label_utterances(dialogue))\n    return pd.DataFrame(all_labeled_data, columns=['Tokens', 'Labels'])\n    \n# Create DataFrames of labeled utterances\ntrain_df = toDF(train_data_filtered)\ntest_df = toDF(test_data_filtered)\nval_df = toDF(val_data_filtered)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T09:12:29.106153Z","iopub.execute_input":"2023-11-21T09:12:29.106472Z","iopub.status.idle":"2023-11-21T09:12:33.722876Z","shell.execute_reply.started":"2023-11-21T09:12:29.106445Z","shell.execute_reply":"2023-11-21T09:12:33.721832Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print(train_df.shape)\nprint(train_df[\"Tokens\"].iloc[9])\nprint(train_df[\"Labels\"].iloc[9])","metadata":{"execution":{"iopub.status.busy":"2023-11-21T09:12:33.724306Z","iopub.execute_input":"2023-11-21T09:12:33.724614Z","iopub.status.idle":"2023-11-21T09:12:33.735041Z","shell.execute_reply.started":"2023-11-21T09:12:33.724587Z","shell.execute_reply":"2023-11-21T09:12:33.734084Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"(28928, 2)\n['your', 'booking', 'was', 'successful', '.', 'your', 'reference', 'number', 'is', 'fr', '##g', '##z', '##w', '##q', '##l', '##2', '.', 'may', 'i', 'help', 'you', 'further', '?']\n['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ref', 'I-ref', 'I-ref', 'I-ref', 'I-ref', 'I-ref', 'I-ref', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n","output_type":"stream"}]},{"cell_type":"code","source":"\nall_labels = [label for sublist in train_df['Labels'].tolist() for label in sublist]\nall_labels += [label for sublist in val_df['Labels'].tolist() for label in sublist]\nall_labels += [label for sublist in test_df['Labels'].tolist() for label in sublist]\nunique_labels = sorted(set(all_labels))\n\nunique_labels.__sizeof__()\n\nprint(unique_labels)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T09:12:33.736532Z","iopub.execute_input":"2023-11-21T09:12:33.736837Z","iopub.status.idle":"2023-11-21T09:12:33.793356Z","shell.execute_reply.started":"2023-11-21T09:12:33.736809Z","shell.execute_reply":"2023-11-21T09:12:33.792411Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"['B-address', 'B-area', 'B-arriveby', 'B-bookday', 'B-bookpeople', 'B-bookstay', 'B-booktime', 'B-choice', 'B-day', 'B-department', 'B-departure', 'B-destination', 'B-entrancefee', 'B-food', 'B-leaveat', 'B-name', 'B-openhours', 'B-phone', 'B-postcode', 'B-price', 'B-pricerange', 'B-ref', 'B-stars', 'B-type', 'I-address', 'I-area', 'I-arriveby', 'I-bookday', 'I-bookpeople', 'I-bookstay', 'I-booktime', 'I-choice', 'I-department', 'I-departure', 'I-destination', 'I-entrancefee', 'I-food', 'I-leaveat', 'I-name', 'I-openhours', 'I-phone', 'I-postcode', 'I-price', 'I-pricerange', 'I-ref', 'I-stars', 'I-type', 'O']\n","output_type":"stream"}]},{"cell_type":"code","source":"label_map = {label: i for i, label in enumerate(unique_labels)}","metadata":{"execution":{"iopub.status.busy":"2023-11-21T09:12:33.794660Z","iopub.execute_input":"2023-11-21T09:12:33.795009Z","iopub.status.idle":"2023-11-21T09:12:33.799645Z","shell.execute_reply.started":"2023-11-21T09:12:33.794976Z","shell.execute_reply":"2023-11-21T09:12:33.798741Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def create_dataset(df, tokenizer, label_map):\n    # Lists to store the tokenized inputs and labels\n    input_ids = []\n    attention_masks = []\n    label_ids = []\n\n    # Iterate over the DataFrame rows\n    for _, row in df.iterrows():\n        tokens = row['Tokens']\n        labels = row['Labels']\n        \n        # Convert the IOB labels to their corresponding IDs\n        label_ids_for_tokens = [label_map[label] for label in labels]\n\n        encoded_input = tokenizer(\n            tokens,\n            is_split_into_words=True,\n            add_special_tokens=True,\n            return_attention_mask=True,\n            padding='max_length',\n            truncation=True,\n            max_length=256,\n            return_offsets_mapping=True\n        )\n        \n        # Create an empty array to hold the final label IDs\n        aligned_labels = np.ones(len(encoded_input['input_ids']), dtype=int) * -100\n\n        # Set labels using the word_ids to align them with tokens\n        for i, word_id in enumerate(encoded_input.word_ids()):\n            if word_id is not None:\n                aligned_labels[i] = label_ids_for_tokens[word_id]\n\n        # Append the results to the lists\n        input_ids.append(encoded_input['input_ids'])\n        attention_masks.append(encoded_input['attention_mask'])\n        label_ids.append(aligned_labels.tolist())\n\n    # Convert lists to tensors\n    input_ids = torch.tensor(input_ids, dtype=torch.long)\n    attention_masks = torch.tensor(attention_masks, dtype=torch.long)\n    label_ids = torch.tensor(label_ids, dtype=torch.long)\n\n    # Create the TensorDataset\n    dataset = TensorDataset(input_ids, attention_masks, label_ids)\n\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2023-11-21T09:12:33.800919Z","iopub.execute_input":"2023-11-21T09:12:33.801295Z","iopub.status.idle":"2023-11-21T09:12:33.818660Z","shell.execute_reply.started":"2023-11-21T09:12:33.801242Z","shell.execute_reply":"2023-11-21T09:12:33.817822Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(create_dataset(train_df,tokenizer,label_map), batch_size=16, shuffle=True)\nval_dataloader = DataLoader(create_dataset(val_df,tokenizer,label_map), batch_size=16, shuffle=True)\ntest_dataloader = DataLoader(create_dataset(test_df,tokenizer,label_map), batch_size=16, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T09:12:33.821393Z","iopub.execute_input":"2023-11-21T09:12:33.821700Z","iopub.status.idle":"2023-11-21T09:12:54.863643Z","shell.execute_reply.started":"2023-11-21T09:12:33.821674Z","shell.execute_reply":"2023-11-21T09:12:54.862625Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from transformers import BertForTokenClassification, BertConfig\n\n# Define the number of labels\nnum_labels = len(label_map)  # Make sure label_map is defined in your environment\n\n# Create a configuration object with `num_labels` set\nconfig = BertConfig.from_pretrained('bert-base-uncased', num_labels=num_labels)\n\n# Create the model with the standard token classification head\nmodel = BertForTokenClassification(config).to(device)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T09:12:54.865075Z","iopub.execute_input":"2023-11-21T09:12:54.865473Z","iopub.status.idle":"2023-11-21T09:13:00.073307Z","shell.execute_reply.started":"2023-11-21T09:12:54.865435Z","shell.execute_reply":"2023-11-21T09:13:00.072391Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\noptimizer = torch.optim.Adam(model.parameters(), lr=3e-5)\ncriterion = nn.CrossEntropyLoss(ignore_index=-100)\nepochs = 10\npatience = 0\n\nbest_val_loss = float('inf')\npatience_counter = 0\n\nfor epoch in range(epochs):\n    model.train()\n    train_loss = 0\n    train_progress_bar = tqdm(train_dataloader, desc=f'Epoch {epoch+1}/{epochs} Training', leave=False)\n    \n    for batch in train_progress_bar:\n        batch = tuple(t.to(device) for t in batch)\n        b_input_ids, b_input_mask, b_labels = batch\n        optimizer.zero_grad()\n        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n        train_progress_bar.set_postfix(train_loss=loss.item())\n    \n    avg_train_loss = train_loss / len(train_dataloader)\n    print(f'Epoch {epoch + 1}/{epochs} | Train Loss: {avg_train_loss}')\n\n    # Validation phase\n    model.eval()\n    val_loss = 0\n    val_progress_bar = tqdm(val_dataloader, desc=f'Epoch {epoch+1}/{epochs} Validation', leave=False)\n    for batch in val_progress_bar:\n        batch = tuple(t.to(device) for t in batch)\n        b_input_ids, b_input_mask, b_labels = batch\n        with torch.no_grad():\n            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n            loss = outputs.loss\n            val_loss += loss.item()\n            val_progress_bar.set_postfix(val_loss=loss.item())\n    \n    avg_val_loss = val_loss / len(val_dataloader)\n    print(f'Epoch {epoch + 1}/{epochs} | Validation Loss: {avg_val_loss}')\n\n    # Check if the validation loss is lower than the best one seen so far\n    if avg_val_loss < best_val_loss:\n        best_val_loss = avg_val_loss\n        patience_counter = 0\n        torch.save(model.state_dict(), f'checkpoint_epoch_{epoch+1}.pt')\n    else:\n        patience_counter += 1\n        if patience_counter >= patience:\n            print('Early stopping!')\n            break\n        \ntorch.save(model.state_dict(), 'final_model.pt')\nprint('Training complete. Final model saved.')","metadata":{"execution":{"iopub.status.busy":"2023-11-21T09:38:56.256005Z","iopub.execute_input":"2023-11-21T09:38:56.256723Z","iopub.status.idle":"2023-11-21T10:26:05.008282Z","shell.execute_reply.started":"2023-11-21T09:38:56.256686Z","shell.execute_reply":"2023-11-21T10:26:05.006941Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"Epoch 1/10 Training:   0%|          | 0/1808 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 1/10 | Train Loss: 0.15099310976905395\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1/10 Validation:   0%|          | 0/130 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 1/10 | Validation Loss: 0.13690484469899764\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2/10 Training:   0%|          | 0/1808 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 2/10 | Train Loss: 0.11545093324544337\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2/10 Validation:   0%|          | 0/130 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 2/10 | Validation Loss: 0.11739960986261185\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3/10 Training:   0%|          | 0/1808 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 3/10 | Train Loss: 0.0996443398365858\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3/10 Validation:   0%|          | 0/130 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 3/10 | Validation Loss: 0.10952364783017682\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4/10 Training:   0%|          | 0/1808 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 4/10 | Train Loss: 0.08679466628607577\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4/10 Validation:   0%|          | 0/130 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 4/10 | Validation Loss: 0.11265308002296548\nEarly stopping!\nTraining complete. Final model saved.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install seqeval\nfrom seqeval.metrics import classification_report as seqeval_classification_report\nimport numpy as np\nimport torch\n\n# Reverse the label map to translate from numeric to string labels\nlabel_map_reverse = {v: k for k, v in label_map.items()}\n\nmodel.eval()\ntotal_loss = 0\nall_predictions = []\nall_true_labels = []\n\nwith torch.no_grad():\n    for batch in test_dataloader:\n        batch = tuple(t.to(device) for t in batch)\n        b_input_ids, b_attention_masks, b_labels = batch\n\n        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_attention_masks, labels=b_labels)\n        loss = outputs.loss\n        total_loss += loss.item()\n\n        # Move logits and labels to CPU\n        logits = outputs.logits.detach().cpu().numpy()\n        label_ids = b_labels.to('cpu').numpy()\n\n        # Convert logits to token predictions\n        predictions = np.argmax(logits, axis=-1)\n\n        # For each item in the batch...\n        for i in range(b_input_ids.size(0)):\n            pred_label_sequence = [label_map_reverse[pred_id] for j, pred_id in enumerate(predictions[i]) if b_attention_masks[i][j] != 0 and pred_id != -100][1:-1]\n\n            true_label_sequence = [label_map_reverse[label_id] for j, label_id in enumerate(label_ids[i]) if b_attention_masks[i][j] != 0 and label_id != -100]\n\n            # Ensure the true and predicted sequences have the same length\n            if len(true_label_sequence) != len(pred_label_sequence):\n                print(f\"Length mismatch in sequence {i}: true labels {len(true_label_sequence)} vs. predicted labels {len(pred_label_sequence)}\")\n                # Output the actual sequences to help diagnose the issue\n                print(\"True labels:\", true_label_sequence)\n                print(\"Pred labels:\", pred_label_sequence)\n                # continue  # Skip appending these labels to avoid the ValueError in seqeval\n\n            # ...extend the true labels and predicted labels lists\n            all_true_labels.append(true_label_sequence)\n            all_predictions.append(pred_label_sequence)\n\n# Calculate average loss over all the batches\navg_loss = total_loss / len(test_dataloader)\nprint(f\"Test loss: {avg_loss}\")\n\n# Use seqeval to compute a classification report\nseqeval_report = seqeval_classification_report(all_true_labels, all_predictions)\nprint(seqeval_report)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T10:35:00.809106Z","iopub.execute_input":"2023-11-21T10:35:00.809998Z","iopub.status.idle":"2023-11-21T10:36:09.378044Z","shell.execute_reply.started":"2023-11-21T10:35:00.809967Z","shell.execute_reply":"2023-11-21T10:36:09.376769Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: seqeval in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.24.3)\nRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.2.2)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.11.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\nTest loss: 0.1105246684257535\n              precision    recall  f1-score   support\n\n     address       0.47      0.68      0.56        79\n        area       0.71      0.76      0.73       321\n     bookday       0.88      0.98      0.93       205\n  bookpeople       0.89      0.84      0.86       186\n    bookstay       0.75      0.90      0.82       125\n    booktime       0.83      0.93      0.88       114\n      choice       0.87      0.86      0.86       215\n        food       0.84      0.91      0.88       241\n        name       0.57      0.70      0.63       427\n       phone       0.83      0.94      0.88        53\n    postcode       0.68      0.92      0.78        48\n  pricerange       0.88      0.95      0.92       306\n         ref       0.86      0.93      0.89       147\n       stars       0.93      0.91      0.92       141\n        type       0.52      0.41      0.46       187\n\n   micro avg       0.76      0.82      0.79      2795\n   macro avg       0.77      0.84      0.80      2795\nweighted avg       0.76      0.82      0.79      2795\n\n","output_type":"stream"}]},{"cell_type":"code","source":"def query_model(model, tokenizer, label_map, utterance, device):\n    model.eval()  \n    \n    \n    # Reverse the label map to translate from numeric IDs to string labels\n    label_map_reverse = {v: k for k, v in label_map.items()}\n\n    \n    # Tokenize the new utterance directly with the tokenizer\n    encoded_input = tokenizer(\n        utterance,\n        add_special_tokens=True,\n        return_attention_mask=True,\n        padding='max_length',\n        truncation=True,\n        max_length=256,\n        return_tensors='pt'  # Return PyTorch tensors directly\n    )\n    \n    # Move tensors to the correct device\n    input_ids = encoded_input['input_ids'].to(device)\n    attention_masks = encoded_input['attention_mask'].to(device)\n    \n    with torch.no_grad():\n        outputs = model(input_ids, token_type_ids=None, attention_mask=attention_masks)\n        logits = outputs.logits\n\n    # Convert logits to probabilities and get the most likely label index\n    predictions = torch.argmax(logits, dim=2).squeeze().tolist()\n\n    # Map predictions to label strings, ignoring -100 and padding tokens\n    predicted_labels = [label_map_reverse.get(label_id) for label_id, mask in zip(predictions, attention_masks.squeeze().tolist()) if mask != 0 and label_id != -100]\n\n    return predicted_labels\n\n# Example usage\nnew_utterance = \"I would like to book a table for two at a Mexican restaurant.\"\npredicted_labels = query_model(model, tokenizer, label_map, new_utterance, device)\nprint(predicted_labels)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T10:36:28.349881Z","iopub.execute_input":"2023-11-21T10:36:28.350569Z","iopub.status.idle":"2023-11-21T10:36:28.377508Z","shell.execute_reply.started":"2023-11-21T10:36:28.350533Z","shell.execute_reply":"2023-11-21T10:36:28.376537Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-bookpeople', 'O', 'O', 'B-food', 'O', 'O', 'O']\n","output_type":"stream"}]}]}